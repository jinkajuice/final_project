{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","mount_file_id":"1LnRqESoiujxN30r9uZ_LX5JRp2SjS4n3","authorship_tag":"ABX9TyMmE2eAe9Nh6YHa+af26fL4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"479f22e3391d417fbcdad35970a903bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a80367fdc25481ab1f0cefa9e54e735","IPY_MODEL_d6d2edd69e7d4c64963baaf6d6a28549","IPY_MODEL_099439444d8d4bd59209b47e14ecfcea"],"layout":"IPY_MODEL_3d6f0cb33fc441c5b7314de53b2bb69c"}},"2a80367fdc25481ab1f0cefa9e54e735":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9b121637af642899bac4718ad8f1756","placeholder":"​","style":"IPY_MODEL_1b9c666cd2864fe1a386c58016122f98","value":"Downloading builder script: 100%"}},"d6d2edd69e7d4c64963baaf6d6a28549":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90f701c5ad794ec199f2b5ef10a68702","max":6338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85377c87a98b48b8870e41415f6ef110","value":6338}},"099439444d8d4bd59209b47e14ecfcea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5fd1614b0754349b67d7f1af4cb273c","placeholder":"​","style":"IPY_MODEL_da3f1fdba6ec44db8ef1fae6296b74a5","value":" 6.34k/6.34k [00:00&lt;00:00, 519kB/s]"}},"3d6f0cb33fc441c5b7314de53b2bb69c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9b121637af642899bac4718ad8f1756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b9c666cd2864fe1a386c58016122f98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90f701c5ad794ec199f2b5ef10a68702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85377c87a98b48b8870e41415f6ef110":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5fd1614b0754349b67d7f1af4cb273c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da3f1fdba6ec44db8ef1fae6296b74a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# Install required packages\n","!pip install -q \\\n","    \"pyarrow<15.0.0\" \\\n","    transformers \\\n","    datasets \\\n","    tokenizers \\\n","    seqeval \\\n","    tensorflow_probability --upgrade \\\n","    evaluate \\\n","    hyperopt \\\n","    \"ray[tune]\""],"metadata":{"collapsed":true,"id":"H0SYPPX6Nf41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727023593356,"user_tz":-60,"elapsed":15227,"user":{"displayName":"Jason T","userId":"07906216535027275286"}},"outputId":"1adeb551-d3a9-4c05-f88f-64ab1e2c679e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# Load libraries\n","import torch\n","from datasets import load_from_disk, DatasetDict\n","\n","from transformers import (\n","    AutoTokenizer,\n","    DataCollatorForTokenClassification,\n","    AutoModelForTokenClassification,\n","    TrainingArguments,\n","    Trainer\n",")\n","\n","import numpy as np\n","import evaluate\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","from sklearn.preprocessing import MultiLabelBinarizer"],"metadata":{"id":"d3mcfvlxKwnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load dataset\n","finer = load_from_disk(\"/content/drive/MyDrive/Code/hfdata_finer.json\")"],"metadata":{"id":"51cris7qKzWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set model\n","model_checkpoint = \"bert-base-cased\"\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","\n","def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples[f\"ner_tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:  # Set the special tokens to -100.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                label_ids.append(label[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs\n","\n","# Create tokenized dataset\n","tokenized_finer = finer.map(tokenize_and_align_labels, batched=True)\n","tokenized_finer"],"metadata":{"id":"jOUsTVk_Li1o","executionInfo":{"status":"ok","timestamp":1727026813891,"user_tz":-60,"elapsed":1550,"user":{"displayName":"Jason T","userId":"07906216535027275286"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f45e60e-fbfb-4660-d76a-6bad935a99ae"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 3187\n","    })\n","    test: Dataset({\n","        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 903\n","    })\n","    valid: Dataset({\n","        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 464\n","    })\n","})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Show example of tokenized input sequence\n","example = finer[\"train\"][0]\n","tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","print(tokens)"],"metadata":{"id":"rzVzROpMMagv","executionInfo":{"status":"ok","timestamp":1727023745053,"user_tz":-60,"elapsed":1265,"user":{"displayName":"Jason T","userId":"07906216535027275286"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2898086f-f8fe-4ce3-d5af-811d50527d16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['[CLS]', 'Following', 'the', 'closing', 'bell', ',', 'American', 'Express', '(', 'A', '##X', '##P', ')', 'reported', 'weaker', 'earnings', 'and', 'revenue', 'than', 'analysts', 'anticipated', '.', '[SEP]']\n"]}]},{"cell_type":"code","source":["# Initialise data_collator for token classification\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","# Load seqeval\n","seqeval = evaluate.load(\"seqeval\")\n","\n","# Map and define text and numeral labels\n","label_list = [\"O\",\"B-PER\",\"I-PER\",\"B-LOC\",\"I-LOC\",\"B-ORG\",\"I-ORG\"]\n","\n","id2label = {\n","    0: \"O\",\n","    1: \"B-PER\",\n","    2: \"I-PER\",\n","    3: \"B-LOC\",\n","    4: \"I-LOC\",\n","    5: \"B-ORG\",\n","    6: \"I-ORG\"\n","}\n","\n","label2id = {\n","    \"O\": 0,\n","    \"B-PER\": 1,\n","    \"I-PER\": 2,\n","    \"B-LOC\": 3,\n","    \"I-LOC\": 4,\n","    \"B-ORG\": 5,\n","    \"I-ORG\": 6\n","}\n","\n","labels = [label_list[i] for i in example[f\"ner_tags\"]]\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(p.predictions, axis=2)\n","\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    mlb = MultiLabelBinarizer()\n","    true_labels = mlb.fit_transform(true_labels)\n","    true_predictions = mlb.transform(true_predictions)\n","\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(true_labels, true_predictions, average='macro')\n","    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(true_labels, true_predictions, average='micro')\n","    accuracy = accuracy_score(true_labels, true_predictions)\n","\n","    return {\n","        'macro_precision': precision_macro,\n","        'macro_recall': recall_macro,\n","        'macro_f1': f1_macro,\n","        'micro_precision': precision_micro,\n","        'micro_recall': recall_micro,\n","        'micro_f1': f1_micro,\n","        'accuracy': accuracy\n","    }"],"metadata":{"id":"bf8_zd-ndrkn","executionInfo":{"status":"ok","timestamp":1727023765744,"user_tz":-60,"elapsed":2566,"user":{"displayName":"Jason T","userId":"07906216535027275286"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["479f22e3391d417fbcdad35970a903bb","2a80367fdc25481ab1f0cefa9e54e735","d6d2edd69e7d4c64963baaf6d6a28549","099439444d8d4bd59209b47e14ecfcea","3d6f0cb33fc441c5b7314de53b2bb69c","f9b121637af642899bac4718ad8f1756","1b9c666cd2864fe1a386c58016122f98","90f701c5ad794ec199f2b5ef10a68702","85377c87a98b48b8870e41415f6ef110","b5fd1614b0754349b67d7f1af4cb273c","da3f1fdba6ec44db8ef1fae6296b74a5"]},"outputId":"d2c6ec66-5b92-4047-a1bf-135fd1169e5e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"479f22e3391d417fbcdad35970a903bb"}},"metadata":{}}]},{"cell_type":"code","source":["# Train bert-large-case using best hyperparameters from bert-base-cased protocol\n","model = AutoModelForTokenClassification.from_pretrained(\n","    'bert-large-cased',\n","    num_labels=len(id2label),\n","    id2label=id2label,\n","    label2id=label2id,\n",")\n","\n","# Train model with best hyperparameters\n","training_args = TrainingArguments(\n","    \"bert-finetuned-ner\",\n","    num_train_epochs=5,\n","    learning_rate=8.288916866885136e-06,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_finer[\"train\"],\n","    eval_dataset=tokenized_finer[\"valid\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"id":"GutXBl5G03hV","executionInfo":{"status":"ok","timestamp":1727025885357,"user_tz":-60,"elapsed":463016,"user":{"displayName":"Jason T","userId":"07906216535027275286"}},"outputId":"53143580-aab7-47a9-ef00-89c167932594"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 07:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Macro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.045731</td>\n","      <td>0.917170</td>\n","      <td>0.936225</td>\n","      <td>0.925547</td>\n","      <td>0.947315</td>\n","      <td>0.964912</td>\n","      <td>0.956033</td>\n","      <td>0.864224</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.035888</td>\n","      <td>0.930278</td>\n","      <td>0.950861</td>\n","      <td>0.939853</td>\n","      <td>0.960163</td>\n","      <td>0.970072</td>\n","      <td>0.965092</td>\n","      <td>0.898707</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.095600</td>\n","      <td>0.037233</td>\n","      <td>0.934364</td>\n","      <td>0.956825</td>\n","      <td>0.944618</td>\n","      <td>0.962245</td>\n","      <td>0.973168</td>\n","      <td>0.967676</td>\n","      <td>0.905172</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.095600</td>\n","      <td>0.038840</td>\n","      <td>0.942350</td>\n","      <td>0.961244</td>\n","      <td>0.951313</td>\n","      <td>0.966292</td>\n","      <td>0.976264</td>\n","      <td>0.971253</td>\n","      <td>0.915948</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.015400</td>\n","      <td>0.040110</td>\n","      <td>0.936741</td>\n","      <td>0.959200</td>\n","      <td>0.947177</td>\n","      <td>0.962322</td>\n","      <td>0.975232</td>\n","      <td>0.968734</td>\n","      <td>0.909483</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1000, training_loss=0.05548418760299682, metrics={'train_runtime': 461.274, 'train_samples_per_second': 34.546, 'train_steps_per_second': 2.168, 'total_flos': 1972632486298188.0, 'train_loss': 0.05548418760299682, 'epoch': 5.0})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Evaluate test dataset and print results.\n","res = trainer.evaluate(tokenized_finer[\"test\"])\n","\n","for metric_name, metric_value in res.items():\n","    print(f\"{metric_name}: {metric_value:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"lGCS4KR05Fp0","executionInfo":{"status":"ok","timestamp":1727026450747,"user_tz":-60,"elapsed":5931,"user":{"displayName":"Jason T","userId":"07906216535027275286"}},"outputId":"7d6342c1-111a-43dd-e216-aa8321124b18"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [57/57 00:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.0468\n","eval_macro_precision: 0.9505\n","eval_macro_recall: 0.9461\n","eval_macro_f1: 0.9473\n","eval_micro_precision: 0.9618\n","eval_micro_recall: 0.9711\n","eval_micro_f1: 0.9664\n","eval_accuracy: 0.8815\n","eval_runtime: 5.6388\n","eval_samples_per_second: 160.1420\n","eval_steps_per_second: 10.1090\n","epoch: 5.0000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"sf_afTAJzDd-"},"execution_count":null,"outputs":[]}]}